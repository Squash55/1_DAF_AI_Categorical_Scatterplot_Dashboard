
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import openai
import os
from dotenv import load_dotenv

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

st.set_page_config(page_title="Air Force AI Dashboard", layout="wide")

# Load data
uploaded_file = st.file_uploader("Upload a new Air Force dataset (CSV)", type=["csv"])
if uploaded_file:
    df = pd.read_csv(uploaded_file)
    data_source = "Uploaded CSV"
else:
    df = pd.read_csv("airforce_data.csv")
    data_source = "Default artificial dataset"

# -------------------------------
# üìò Dashboard Header
# -------------------------------
st.markdown("""
## üìò Analysis Methods & Auto-Update Capabilities

This dashboard uses a combination of **rule-based logic** and optional **GPT-based AI interpretations** to uncover insights in your dataset. All interpretations **auto-update** whenever you upload a new dataset or adjust filters.

- üß† **Rule-Based Insights** are recalculated instantly from live data using grouping, aggregation, and threshold logic.
- ü§ñ **GPT-Based Interpretations** can be refreshed on demand, providing flexible narrative insights powered by AI.
- üìâ **Missing Data Advisory** is dynamically generated by GPT to identify important variables not present in the dataset.

This ensures your results are always **current, explainable, and aligned with the structure of your data.**  
All insights are clearly tagged with their method of origin for full transparency.
""", unsafe_allow_html=True)

# -------------------------------
# Generate interpretations
# -------------------------------
def generate_rule_based_insights(df):
    insights = []
    grouped = df.groupby('Mission Type')
    for mission, group in grouped:
        breach_rate = group['Breach History'].mean()
        high_risk = group[group['Cyber Risk Level'] >= 2]
        high_risk_breach_rate = high_risk['Breach History'].mean() if not high_risk.empty else 0
        insights.append(
            f"üß† [Rule-Based] **{mission}** missions have a **{breach_rate:.0%} breach rate**, "
            f"with **{high_risk_breach_rate:.0%} breach rate at risk levels 2‚Äì3.**"
        )
    return insights

def generate_gpt_insights(df):
    if openai.api_key is None:
        return ["‚ö†Ô∏è [GPT-Based] OpenAI API key not found. GPT insights are disabled."]
    prompt = f"""You are an AI data analyst. The dataset includes these columns: {list(df.columns)}. 
Generate executive-level insights about breach patterns across mission types using clear, bullet-style summaries."""
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.5
        )
        return ["ü§ñ [GPT-Based] " + line for line in response['choices'][0]['message']['content'].split('\n') if line.strip()]
    except Exception as e:
        return [f"‚ö†Ô∏è GPT error: {e}"]

# -------------------------------
# Visualization
# -------------------------------
jitter_strength = st.slider("Jitter Strength", 0, 30, 10, 1)

fig, ax = plt.subplots(figsize=(10, 6))
x = np.linspace(-0.5, 3.5, 500)
y = np.linspace(-1, 4.5, 500)
X, Y = np.meshgrid(x, y)
Z = 1 / (1 + np.exp(-(X - 1.5) * 5))
ax.imshow(Z, extent=[-0.5, 3.5, -1, 4.5], origin='lower', cmap='bwr', alpha=0.2, aspect='auto')

df['x'] = df['Mission Type'].map({'Surveillance': 0, 'Training': 1, 'Combat': 2, 'Logistics': 3}) +           np.random.normal(0, jitter_strength / 100, size=len(df))

for label, color in zip([0, 1], ['blue', 'red']):
    subset = df[df['Breach History'] == label]
    ax.scatter(subset['x'], subset['Cyber Risk Level'], color=color,
               label='No Breach' if label == 0 else 'Breach', edgecolor='k', alpha=0.8)

ax.set_xticks(range(4))
ax.set_xticklabels(['Surveillance', 'Training', 'Combat', 'Logistics'], rotation=15)
ax.set_yticks(range(-1, 5))
ax.set_ylabel('Cyber Risk Level')
ax.set_xlabel('Mission Type')
ax.legend(title='Breach History')
st.pyplot(fig)

# -------------------------------
# Display interpretations
# -------------------------------
st.subheader("üìä Auto-Generated Interpretations")
col1, col2 = st.columns(2)
with col1:
    st.markdown("### üß† Rule-Based")
    for i in generate_rule_based_insights(df):
        st.markdown(i)
with col2:
    st.markdown("### ü§ñ GPT-Based")
    for i in generate_gpt_insights(df):
        st.markdown(i)

# -------------------------------
# Missing Data Advisory (GPT)
# -------------------------------
if openai.api_key:
    disclaimer_prompt = f"""You are reviewing an Air Force dataset with columns: {list(df.columns)}.
List 3‚Äì5 relevant fields that are missing and should be included in future analyses. 
Add a short one-sentence rationale and tag each with High, Medium, or Optional priority."""
    try:
        resp = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[{"role": "user", "content": disclaimer_prompt}],
            temperature=0.4
        )
        st.subheader("üìâ Missing Data Disclaimer (AI-Generated)")
        for line in resp['choices'][0]['message']['content'].split('\n'):
            st.markdown("üõ†Ô∏è " + line)
    except Exception as e:
        st.error(f"Error retrieving GPT disclaimer: {e}")
else:
    st.warning("GPT missing data advisory disabled. No API key detected.")
