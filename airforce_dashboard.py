import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import openai
import os
from dotenv import load_dotenv

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

st.set_page_config(page_title="Air Force Categorical Scatterplot Dashboard", layout="wide")

# Load data
uploaded_file = st.file_uploader("Upload a new Air Force dataset (CSV)", type=["csv"])
if uploaded_file:
    df = pd.read_csv(uploaded_file)
    data_source = "Uploaded CSV"
else:
    df = pd.read_csv("airforce_data.csv")
    data_source = "Default artificial dataset"

# Dashboard header
st.markdown("""
## ğŸ“˜ Analysis Methods & Auto-Update Capabilities

This dashboard uses a combination of **rule-based logic** and optional **GPT-based AI interpretations** to uncover insights in your dataset. All interpretations **auto-update** whenever you upload a new dataset or adjust filters.

- ğŸ§  **Rule-Based Insights** are recalculated instantly from live data using grouping, aggregation, and threshold logic.
- ğŸ¤– **GPT-Based Interpretations** can be refreshed on demand, providing flexible narrative insights powered by AI.
- ğŸ“‰ **Missing Data Advisory** is dynamically generated by GPT to identify important variables not present in the dataset.

This ensures your results are always **current, explainable, and aligned with the structure of your data.**  
All insights are clearly tagged with their method of origin for full transparency.
""", unsafe_allow_html=True)

# Jitter sliders
col1, col2 = st.columns(2)
x_jitter = col1.slider("Horizontal Jitter", 0, 30, 10, 1)
y_jitter = col2.slider("Vertical Jitter", 0, 30, 10, 1)

# Convert categorical x-axis to numeric positions with jitter
mission_map = {'Surveillance': 0, 'Training': 1, 'Combat': 2, 'Logistics': 3}
df['x'] = df['Mission Type'].map(mission_map) + np.random.normal(0, x_jitter / 100, size=len(df))

# Plotting
fig, ax = plt.subplots(figsize=(10, 6))
x = np.linspace(-0.5, 3.5, 500)
y = np.linspace(-1, 4.5, 500)
X, Y = np.meshgrid(x, y)

# Simulated 2D risk surface: high risk = top-right, low = bottom-left
Z = np.exp(-((X - 2.2)**2 / 1.2 + (Y - 3)**2 / 2))

# Normalize to 0â€“1 range for color scaling
Z = (Z - Z.min()) / (Z.max() - Z.min())

# Apply color gradient
ax.imshow(Z, extent=[-0.5, 3.5, -1, 4.5], origin='lower', cmap='bwr', alpha=0.25, aspect='auto')


# Scatter points with both x and y jitter
for label, color in zip([0, 1], ['blue', 'red']):
    subset = df[df['Breach History'] == label]
    subset_y = subset['Cyber Risk Level'] + np.random.normal(0, y_jitter / 100, size=len(subset))
    ax.scatter(subset['x'], subset_y, color=color,
               label='No Breach' if label == 0 else 'Breach', edgecolor='k', alpha=0.8)

ax.set_xticks(range(4))
ax.set_xticklabels(['Surveillance', 'Training', 'Combat', 'Logistics'], rotation=15)
ax.set_yticks(range(-1, 5))
ax.set_ylabel('Cyber Risk Level')
ax.set_xlabel('Mission Type')
ax.legend(title='Breach History')
st.pyplot(fig)

# Rule-based insights
def generate_rule_based_insights(df):
    insights = []
    grouped = df.groupby('Mission Type')
    for mission, group in grouped:
        breach_rate = group['Breach History'].mean()
        high_risk = group[group['Cyber Risk Level'] >= 2]
        high_risk_breach_rate = high_risk['Breach History'].mean() if not high_risk.empty else 0
        insights.append(
            f"ğŸ§  [Rule-Based] **{mission}** missions have a **{breach_rate:.0%} breach rate**, "
            f"with **{high_risk_breach_rate:.0%} breach rate at risk levels 2â€“3.**"
        )
    return insights

# GPT-based insights
def generate_gpt_insights(df):
    if openai.api_key is None:
        return ["âš ï¸ [GPT-Based] OpenAI API key not found. GPT insights are disabled."]
    prompt = f"You are an AI analyst reviewing a dataset with columns: {list(df.columns)}. " \
             f"Generate clear, executive-style insights about breach risk by mission type."
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.5
        )
        return ["ğŸ¤– [GPT-Based] " + line for line in response['choices'][0]['message']['content'].split('\n') if line.strip()]
    except Exception as e:
        return [f"âš ï¸ GPT error: {e}"]

# Display insights side by side
st.subheader("ğŸ“Š Auto-Generated Interpretations")
col1, col2 = st.columns(2)
with col1:
    st.markdown("### ğŸ§  Rule-Based")
    for i in generate_rule_based_insights(df):
        st.markdown(i)
with col2:
    st.markdown("### ğŸ¤– GPT-Based")
    for i in generate_gpt_insights(df):
        st.markdown(i)

# Missing data disclaimer
if openai.api_key:
    disclaimer_prompt = f"You are reviewing an Air Force dataset with columns: {list(df.columns)}. " \
                        "List 3â€“5 important but missing fields that should be added for better analysis. " \
                        "Include rationale and tag each as High, Medium, or Optional priority."
    try:
        resp = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[{"role": "user", "content": disclaimer_prompt}],
            temperature=0.4
        )
        st.subheader("ğŸ“‰ Missing Data Disclaimer (AI-Generated)")
        for line in resp['choices'][0]['message']['content'].split('\n'):
            st.markdown("ğŸ› ï¸ " + line)
    except Exception as e:
        st.error(f"Error retrieving GPT disclaimer: {e}")
else:
    st.warning("GPT missing data advisory disabled. No API key detected.")
